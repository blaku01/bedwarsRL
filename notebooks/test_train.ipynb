{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import (\n",
    "    Compose,\n",
    "    DoubleToFloat,\n",
    "    ObservationNorm,\n",
    "    StepCounter,\n",
    "    TransformedEnv,\n",
    ")\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from src.environments.gym_1_vs_1 import MinecraftGym"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:27:32.827832Z",
     "start_time": "2024-04-21T15:27:29.186957Z"
    }
   },
   "id": "44217d8a0a010852",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "num_cells = 256  # number of cells in each layer i.e. output dim.\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "\n",
    "frames_per_batch = 200\n",
    "# For a complete training, bring the number of frames up to 1M\n",
    "total_frames = 10_000\n",
    "\n",
    "\n",
    "sub_batch_size = 64  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
    "num_epochs = 10  # optimisation steps per batch of data collected\n",
    "clip_epsilon = (\n",
    "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
    ")\n",
    "gamma = 0.99\n",
    "lmbda = 0.95\n",
    "entropy_eps = 1e-4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:27:32.843892Z",
     "start_time": "2024-04-21T15:27:32.829827Z"
    }
   },
   "id": "af9e316b782e52bb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:27:39.164513Z",
     "start_time": "2024-04-21T15:27:32.844889Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_reset() got an unexpected keyword argument 'tensordict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 13\u001B[0m\n\u001B[0;32m      1\u001B[0m base_env \u001B[38;5;241m=\u001B[39m MinecraftGym(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m      3\u001B[0m env \u001B[38;5;241m=\u001B[39m TransformedEnv(\n\u001B[0;32m      4\u001B[0m     base_env,\n\u001B[0;32m      5\u001B[0m     Compose(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     10\u001B[0m     ),\n\u001B[0;32m     11\u001B[0m )\n\u001B[1;32m---> 13\u001B[0m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_stats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormalization constant shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, env\u001B[38;5;241m.\u001B[39mtransform[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mloc\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobservation_spec:\u001B[39m\u001B[38;5;124m\"\u001B[39m, env\u001B[38;5;241m.\u001B[39mobservation_spec)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bedwarsRL\\lib\\site-packages\\torchrl\\envs\\transforms\\transforms.py:2492\u001B[0m, in \u001B[0;36mObservationNorm.init_stats\u001B[1;34m(self, num_iter, reduce_dim, cat_dim, key, keep_dims)\u001B[0m\n\u001B[0;32m   2490\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   2491\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m collected_frames \u001B[38;5;241m<\u001B[39m num_iter:\n\u001B[1;32m-> 2492\u001B[0m     tensordict \u001B[38;5;241m=\u001B[39m \u001B[43mparent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2493\u001B[0m     collected_frames \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tensordict\u001B[38;5;241m.\u001B[39mnumel()\n\u001B[0;32m   2494\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend(tensordict\u001B[38;5;241m.\u001B[39mget(key))\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bedwarsRL\\lib\\site-packages\\torchrl\\envs\\common.py:2376\u001B[0m, in \u001B[0;36mEnvBase.rollout\u001B[1;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, return_contiguous, tensordict, out)\u001B[0m\n\u001B[0;32m   2372\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tensordict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2373\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   2374\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensordict cannot be provided when auto_reset is True\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2375\u001B[0m         )\n\u001B[1;32m-> 2376\u001B[0m     tensordict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2377\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m tensordict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2378\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensordict must be provided when auto_reset is False\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bedwarsRL\\lib\\site-packages\\torchrl\\envs\\common.py:2056\u001B[0m, in \u001B[0;36mEnvBase.reset\u001B[1;34m(self, tensordict, **kwargs)\u001B[0m\n\u001B[0;32m   2053\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tensordict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2054\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assert_tensordict_shape(tensordict)\n\u001B[1;32m-> 2056\u001B[0m tensordict_reset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset(tensordict, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2057\u001B[0m \u001B[38;5;66;03m#        We assume that this is done properly\u001B[39;00m\n\u001B[0;32m   2058\u001B[0m \u001B[38;5;66;03m#        if tensordict_reset.device != self.device:\u001B[39;00m\n\u001B[0;32m   2059\u001B[0m \u001B[38;5;66;03m#            tensordict_reset = tensordict_reset.to(self.device, non_blocking=False)\u001B[39;00m\n\u001B[0;32m   2060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tensordict_reset \u001B[38;5;129;01mis\u001B[39;00m tensordict:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bedwarsRL\\lib\\site-packages\\torchrl\\envs\\transforms\\transforms.py:785\u001B[0m, in \u001B[0;36mTransformedEnv._reset\u001B[1;34m(self, tensordict, **kwargs)\u001B[0m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tensordict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;66;03m# We must avoid modifying the original tensordict so a shallow copy is necessary.\u001B[39;00m\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;66;03m# We just select the input data and reset signal, which is all we need.\u001B[39;00m\n\u001B[0;32m    782\u001B[0m     tensordict \u001B[38;5;241m=\u001B[39m tensordict\u001B[38;5;241m.\u001B[39mselect(\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_keys, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_spec\u001B[38;5;241m.\u001B[39mkeys(\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m), strict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     )\n\u001B[1;32m--> 785\u001B[0m tensordict_reset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_env\u001B[38;5;241m.\u001B[39m_reset(tensordict\u001B[38;5;241m=\u001B[39mtensordict, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    786\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tensordict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;66;03m# make sure all transforms see a source tensordict\u001B[39;00m\n\u001B[0;32m    788\u001B[0m     tensordict \u001B[38;5;241m=\u001B[39m tensordict_reset\u001B[38;5;241m.\u001B[39mempty()\n",
      "\u001B[1;31mTypeError\u001B[0m: _reset() got an unexpected keyword argument 'tensordict'"
     ]
    }
   ],
   "source": [
    "base_env = MinecraftGym(device=device)\n",
    "\n",
    "env = TransformedEnv(\n",
    "    base_env,\n",
    "    Compose(\n",
    "        # normalize observations\n",
    "        ObservationNorm(in_keys=[\"observation\"]),\n",
    "        DoubleToFloat(),\n",
    "        StepCounter(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)\n",
    "\n",
    "print(\"normalization constant shape:\", env.transform[0].loc.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)\n",
    "print(\"input_spec:\", env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-21T15:27:39.165514Z"
    }
   },
   "id": "c0ea9ab6582f787"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
